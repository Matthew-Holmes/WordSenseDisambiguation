{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnning Llama on the prompts\n",
    "\n",
    "Now we can test the full loop, before writing a job manifest, we will:\n",
    "1. load Llama into memory from our pickled weights\n",
    "2. normalised the data chunk to get prompts\n",
    "3. run the LLM on our promps\n",
    "4. save the hidden activations to disk\n",
    "\n",
    "5. (optional) implement caching for the definitions, since they may be shared between multiple words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "project_path = os.path.abspath(\"LLM\")\n",
    "\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama.tokenizer.Tokenizer at 0x7fcc602c8c50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama.tokenizer import Tokenizer\n",
    "\n",
    "tok_path = \"/home/matt/.llama/checkpoints/Llama3.2-1B-hf-tok/tokenizer.model\"\n",
    "tok = Tokenizer(tok_path)\n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-03-11 16:46:13,889:jax._src.xla_bridge:966: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"Data/ModelWeights/llama_jax_weights.pkl\", \"rb\") as f:\n",
    "    params_jax_loaded = pickle.load(f)\n",
    "\n",
    "n_heads = 32\n",
    "n_kv_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Processed/SemCoreChunks/chunk_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import re\n",
    "\n",
    "def fix_whitespace(text):\n",
    "    # Remove spaces before punctuation\n",
    "    text = re.sub(r'\\s+([?.!,;:])', r'\\1', text)\n",
    "    # Ensure space after punctuation if followed by a word (except for some cases like commas within numbers)\n",
    "    text = re.sub(r'([?.!;:])(?=[^\\s])', r'\\1 ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "type series = pd.core.series.Series\n",
    "\n",
    "def prep_row(row: series) -> series:\n",
    "    row[\"all_defs\"] = str.split(row.definitions, '|')\n",
    "    row[\"sentence_str\"]  = ' ' + fix_whitespace(' '.join(str.split(row.sentence, '|')))  \n",
    "    row[\"sentence_toks\"] = tok.encode(row[\"sentence_str\"], bos = False, eos = False)\n",
    "\n",
    "    remaining = row[\"sentence_str\"]\n",
    "\n",
    "    word_start_index = 0\n",
    "\n",
    "    for i in range(row[\"word_loc\"]):\n",
    "        word = tok.decode([row[\"sentence_toks\"][i]])\n",
    "        word_start_index += remaining.find(word)\n",
    "        word_start_index += len(word)\n",
    "        remaining = row[\"sentence_str\"][word_start_index:]\n",
    "\n",
    "\n",
    "    row[\"word_start_index\"] = word_start_index\n",
    "\n",
    "    word_tok_index = 0\n",
    "    i = 0\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        word = tok.decode([row[\"sentence_toks\"][word_tok_index]])\n",
    "        \n",
    "        i += len(word)\n",
    "        \n",
    "        if i > word_start_index:\n",
    "            break\n",
    "        \n",
    "        word_tok_index  += 1\n",
    "\n",
    "    row[\"word_tok_index\"] = word_tok_index\n",
    "\n",
    "    encode = lambda  text : tok.encode(text, bos = False, eos = False)\n",
    "    if len(encode(\" \" + row[\"word\"])) == len(encode(\" \" + row[\"word\"] + \":\")):\n",
    "        return Exception(\"colon was absorbed - changing token embedding!\")\n",
    "    \n",
    "    defs = row[\"definitions\"].split('|')\n",
    "\n",
    "    row[\"definition_prompts\"] = [\" \" + row[\"word\"] + \": \" + d for d in defs]\n",
    "    row[\"definition_toks\"] = [encode(def_prompt) for def_prompt in row[\"definition_prompts\"]]\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 92.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df_new = df.progress_apply(prep_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "      <th>definitions</th>\n",
       "      <th>all_defs</th>\n",
       "      <th>sentence_str</th>\n",
       "      <th>sentence_toks</th>\n",
       "      <th>word_start_index</th>\n",
       "      <th>word_tok_index</th>\n",
       "      <th>definition_prompts</th>\n",
       "      <th>definition_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>How|long|has|it|been|since|you|reviewed|the|ob...</td>\n",
       "      <td>1</td>\n",
       "      <td>long%3:00:02::</td>\n",
       "      <td>primarily temporal sense; being or indicating ...</td>\n",
       "      <td>desire strongly or persistently|primarily temp...</td>\n",
       "      <td>[desire strongly or persistently, primarily te...</td>\n",
       "      <td>How long has it been since you reviewed the o...</td>\n",
       "      <td>[2650, 1317, 706, 433, 1027, 2533, 499, 22690,...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[ long: desire strongly or persistently,  long...</td>\n",
       "      <td>[[1317, 25, 12876, 16917, 477, 23135, 4501], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>been</td>\n",
       "      <td>How|long|has|it|been|since|you|reviewed|the|ob...</td>\n",
       "      <td>4</td>\n",
       "      <td>be%2:42:03::</td>\n",
       "      <td>have the quality of being; (copula, used with ...</td>\n",
       "      <td>a light strong brittle grey toxic bivalent met...</td>\n",
       "      <td>[a light strong brittle grey toxic bivalent me...</td>\n",
       "      <td>How long has it been since you reviewed the o...</td>\n",
       "      <td>[2650, 1317, 706, 433, 1027, 2533, 499, 22690,...</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[ been: a light strong brittle grey toxic biva...</td>\n",
       "      <td>[[1027, 25, 264, 3177, 3831, 95749, 20366, 215...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word                                           sentence  word_loc  \\\n",
       "0  long  How|long|has|it|been|since|you|reviewed|the|ob...         1   \n",
       "1  been  How|long|has|it|been|since|you|reviewed|the|ob...         4   \n",
       "\n",
       "          wordnet                                         definition  \\\n",
       "0  long%3:00:02::  primarily temporal sense; being or indicating ...   \n",
       "1    be%2:42:03::  have the quality of being; (copula, used with ...   \n",
       "\n",
       "                                         definitions  \\\n",
       "0  desire strongly or persistently|primarily temp...   \n",
       "1  a light strong brittle grey toxic bivalent met...   \n",
       "\n",
       "                                            all_defs  \\\n",
       "0  [desire strongly or persistently, primarily te...   \n",
       "1  [a light strong brittle grey toxic bivalent me...   \n",
       "\n",
       "                                        sentence_str  \\\n",
       "0   How long has it been since you reviewed the o...   \n",
       "1   How long has it been since you reviewed the o...   \n",
       "\n",
       "                                       sentence_toks  word_start_index  \\\n",
       "0  [2650, 1317, 706, 433, 1027, 2533, 499, 22690,...                 4   \n",
       "1  [2650, 1317, 706, 433, 1027, 2533, 499, 22690,...                16   \n",
       "\n",
       "   word_tok_index                                 definition_prompts  \\\n",
       "0               1  [ long: desire strongly or persistently,  long...   \n",
       "1               4  [ been: a light strong brittle grey toxic biva...   \n",
       "\n",
       "                                     definition_toks  \n",
       "0  [[1317, 25, 12876, 16917, 477, 23135, 4501], [...  \n",
       "1  [[1027, 25, 264, 3177, 3831, 95749, 20366, 215...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_jax_loaded[\"freqs_cis\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from LLM.llama_jax.model import reporting_transformer\n",
    "\n",
    "\n",
    "jitted_transformer = jax.jit(reporting_transformer, static_argnames=[\"n_heads\", \"n_kv_heads\"])\n",
    "\n",
    "\n",
    "max_tok_len = 256\n",
    "\n",
    "params_jax_loaded[\"freqs_cis\"] = params_jax_loaded[\"freqs_cis\"][0:max_tok_len, :]\n",
    "\n",
    "def pad_toks(toks: List[int]):\n",
    "    to_pad = max_tok_len - len(toks)\n",
    "\n",
    "    if (to_pad < 0):\n",
    "        ret = toks[0:to_pad]\n",
    "    else:\n",
    "        ret = toks + [0] * to_pad\n",
    "\n",
    "    mask = [0 if tok != 0 else -jnp.inf for tok in ret]\n",
    "\n",
    "    return jnp.array(ret)[None, :], jnp.array(mask)\n",
    "\n",
    "\n",
    "def get_activations(toks: List[int]):\n",
    "    padded_toks, mask = pad_toks(toks)\n",
    "    return jitted_transformer(padded_toks, params_jax_loaded, mask, n_heads, n_kv_heads)\n",
    "\n",
    "\n",
    "def LLM_process_row(row: series) -> series:\n",
    "    sentence_acts = get_activations(row.sentence_toks)\n",
    "    def_acts     = [get_activations(def_toks) for def_toks in row.definition_toks]\n",
    "\n",
    "    # TODO - if the data volume is too large, then only store the activations\n",
    "    # near the word itself\n",
    "    row[\"sentence_activations\"] = sentence_acts\n",
    "    row[\"definition_activates\"] = def_acts\n",
    "\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df_new_small = df_new.head(1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [02:38<00:00, 158.19s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "df_new_small = df_new_small.progress_apply(LLM_process_row, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "      <th>definitions</th>\n",
       "      <th>all_defs</th>\n",
       "      <th>sentence_str</th>\n",
       "      <th>sentence_toks</th>\n",
       "      <th>word_start_index</th>\n",
       "      <th>word_tok_index</th>\n",
       "      <th>definition_prompts</th>\n",
       "      <th>definition_toks</th>\n",
       "      <th>sentence_activations</th>\n",
       "      <th>definition_activates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>How|long|has|it|been|since|you|reviewed|the|ob...</td>\n",
       "      <td>1</td>\n",
       "      <td>long%3:00:02::</td>\n",
       "      <td>primarily temporal sense; being or indicating ...</td>\n",
       "      <td>desire strongly or persistently|primarily temp...</td>\n",
       "      <td>[desire strongly or persistently, primarily te...</td>\n",
       "      <td>How long has it been since you reviewed the o...</td>\n",
       "      <td>[2650, 1317, 706, 433, 1027, 2533, 499, 22690,...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[ long: desire strongly or persistently,  long...</td>\n",
       "      <td>[[1317, 25, 12876, 16917, 477, 23135, 4501], [...</td>\n",
       "      <td>[[[[0.0119629 -0.00976562 -0.0106201 ... -0.01...</td>\n",
       "      <td>[[[[[0.000976562 0.0205078 0.0634766 ... -0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word                                           sentence  word_loc  \\\n",
       "0  long  How|long|has|it|been|since|you|reviewed|the|ob...         1   \n",
       "\n",
       "          wordnet                                         definition  \\\n",
       "0  long%3:00:02::  primarily temporal sense; being or indicating ...   \n",
       "\n",
       "                                         definitions  \\\n",
       "0  desire strongly or persistently|primarily temp...   \n",
       "\n",
       "                                            all_defs  \\\n",
       "0  [desire strongly or persistently, primarily te...   \n",
       "\n",
       "                                        sentence_str  \\\n",
       "0   How long has it been since you reviewed the o...   \n",
       "\n",
       "                                       sentence_toks  word_start_index  \\\n",
       "0  [2650, 1317, 706, 433, 1027, 2533, 499, 22690,...                 4   \n",
       "\n",
       "   word_tok_index                                 definition_prompts  \\\n",
       "0               1  [ long: desire strongly or persistently,  long...   \n",
       "\n",
       "                                     definition_toks  \\\n",
       "0  [[1317, 25, 12876, 16917, 477, 23135, 4501], [...   \n",
       "\n",
       "                                sentence_activations  \\\n",
       "0  [[[[0.0119629 -0.00976562 -0.0106201 ... -0.01...   \n",
       "\n",
       "                                definition_activates  \n",
       "0  [[[[[0.000976562 0.0205078 0.0634766 ... -0.01...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 2048)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_small.iloc[0].sentence_activations[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data volume\n",
    "\n",
    "We are seeing roughly 1Mb of data per layer, so 16Mb per sentence/definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "907"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[\"num_defs\"] = df_new[\"definition_toks\"].apply(lambda ds : len(ds))\n",
    "df_new[\"num_defs\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have 1000 setences + definitions an so will be generating 16Gb of data per chunk, and thus would need ~30Tb of storage to process it all!\n",
    "\n",
    "Lets cut down the volume, first lets see what is actually a resonable max token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df_new[\"number_sentence_toks\"] = df_new[\"sentence_toks\"].apply(lambda toks : len(toks))\n",
    "df_new[\"number_def_toks\"] = df_new[\"definition_toks\"].apply(lambda defs_toks : [len(def_toks) for def_toks in defs_toks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean      20.710000\n",
       "std        8.210974\n",
       "min        6.000000\n",
       "25%       13.000000\n",
       "50%       19.000000\n",
       "75%       27.000000\n",
       "max       35.000000\n",
       "Name: number_sentence_toks, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[\"number_sentence_toks\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Third': 13.5, 'Median': 9.0, 'Mean': 10.783902976846747, 'Max': 42}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_values = [num for sublist in df_new['number_def_toks'] for num in sublist]\n",
    "\n",
    "# Compute statistics\n",
    "third = np.percentile(all_values, 75)\n",
    "median = np.median(all_values)\n",
    "mean = np.mean(all_values)\n",
    "max_val = np.max(all_values)\n",
    "\n",
    "# Print results\n",
    "stats = {\n",
    "    \"Third\" : third,\n",
    "    \"Median\": median,\n",
    "    \"Mean\": mean,\n",
    "    \"Max\": max_val,\n",
    "}\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limiting the inputs to 32 tokens looks like it would still keep most of the information we need, the definitions can be clipped from the ends... for the sentences we should clip outwards from the word, luckily we have the word token indices for that\n",
    "\n",
    "That will yield a 3-fold (8x) reduction in data volume to roughly 4Tb. However we will not necessarily process all the data, and 500Mb per chunk seems more manageable for processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching\n",
    "\n",
    "Currently the dataframe based is a bit awkward, it will be easier to extract all the lists of tokens, alongside lookup dicts based on the indices in the dataframe, then convert them to one big input tokens array, which we can chunk and send through the transformer in batches.\n",
    "\n",
    "The outputs can then be unpacked - it might be worth adding an output tensor dimension instead of the list approach currently used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WordSenseDisambiguation",
   "language": "python",
   "name": "wordsensedisambiguation"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
