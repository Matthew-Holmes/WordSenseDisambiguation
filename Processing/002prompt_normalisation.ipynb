{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prompt normalisation\n",
    "\n",
    "In this notebook we develop the functions process a chunk of the semcore dataset into prompts for the model, with variable batch size and maximum sequence length.\n",
    "\n",
    "The goal here is to have the ambiguous word surrounded by a contextual window, for now I'll leave it centred if the window has to be clipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Processed/SemCoreChunks/chunk_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "      <th>definitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>How|long|has|it|been|since|you|reviewed|the|ob...</td>\n",
       "      <td>1</td>\n",
       "      <td>long%3:00:02::</td>\n",
       "      <td>primarily temporal sense; being or indicating ...</td>\n",
       "      <td>desire strongly or persistently|primarily temp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>been</td>\n",
       "      <td>How|long|has|it|been|since|you|reviewed|the|ob...</td>\n",
       "      <td>4</td>\n",
       "      <td>be%2:42:03::</td>\n",
       "      <td>have the quality of being; (copula, used with ...</td>\n",
       "      <td>a light strong brittle grey toxic bivalent met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reviewed</td>\n",
       "      <td>How|long|has|it|been|since|you|reviewed|the|ob...</td>\n",
       "      <td>7</td>\n",
       "      <td>review%2:31:00::</td>\n",
       "      <td>look at again; examine again</td>\n",
       "      <td>a new appraisal or evaluation|an essay or arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>objectives</td>\n",
       "      <td>How|long|has|it|been|since|you|reviewed|the|ob...</td>\n",
       "      <td>9</td>\n",
       "      <td>objective%1:09:00::</td>\n",
       "      <td>the goal intended to be attained (and which is...</td>\n",
       "      <td>the goal intended to be attained (and which is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit</td>\n",
       "      <td>How|long|has|it|been|since|you|reviewed|the|ob...</td>\n",
       "      <td>12</td>\n",
       "      <td>benefit%1:21:00::</td>\n",
       "      <td>financial assistance in time of need</td>\n",
       "      <td>financial assistance in time of need|something...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word                                           sentence  word_loc  \\\n",
       "0        long  How|long|has|it|been|since|you|reviewed|the|ob...         1   \n",
       "1        been  How|long|has|it|been|since|you|reviewed|the|ob...         4   \n",
       "2    reviewed  How|long|has|it|been|since|you|reviewed|the|ob...         7   \n",
       "3  objectives  How|long|has|it|been|since|you|reviewed|the|ob...         9   \n",
       "4     benefit  How|long|has|it|been|since|you|reviewed|the|ob...        12   \n",
       "\n",
       "               wordnet                                         definition  \\\n",
       "0       long%3:00:02::  primarily temporal sense; being or indicating ...   \n",
       "1         be%2:42:03::  have the quality of being; (copula, used with ...   \n",
       "2     review%2:31:00::                       look at again; examine again   \n",
       "3  objective%1:09:00::  the goal intended to be attained (and which is...   \n",
       "4    benefit%1:21:00::               financial assistance in time of need   \n",
       "\n",
       "                                         definitions  \n",
       "0  desire strongly or persistently|primarily temp...  \n",
       "1  a light strong brittle grey toxic bivalent met...  \n",
       "2  a new appraisal or evaluation|an essay or arti...  \n",
       "3  the goal intended to be attained (and which is...  \n",
       "4  financial assistance in time of need|something...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "type series = pd.core.series.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import re\n",
    "\n",
    "def fix_whitespace(text):\n",
    "    # Remove spaces before punctuation\n",
    "    text = re.sub(r'\\s+([?.!,;:])', r'\\1', text)\n",
    "    # Ensure space after punctuation if followed by a word (except for some cases like commas within numbers)\n",
    "    text = re.sub(r'([?.!;:])(?=[^\\s])', r'\\1 ', text)\n",
    "    return text\n",
    "\n",
    "def all_defs(row: series) -> List[str]:\n",
    "    return str.split(row.definitions, '|')\n",
    "\n",
    "def sentence(row: series) -> str:\n",
    "    return ' ' + fix_whitespace(' '.join(str.split(row.sentence, '|'))) # see below for why we add preceding whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['desire strongly or persistently',\n",
       " 'primarily temporal sense; being or indicating a relatively great or greater than average duration or passage of time or a duration as specified',\n",
       " 'primarily spatial sense; of relatively great or greater than average spatial extension or extension as specified',\n",
       " 'of relatively great height; - Sherwood Anderson',\n",
       " 'good at remembering',\n",
       " 'holding securities or commodities in expectation of a rise in prices',\n",
       " '(of speech sounds or syllables) of relatively long duration',\n",
       " 'involving substantial risk',\n",
       " 'planning prudently for the future',\n",
       " 'having or being more than normal or necessary:',\n",
       " 'for an extended time or at a distant time',\n",
       " 'for an extended distance']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_defs(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' How long has it been since you reviewed the objectives of your benefit and service program?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama.tokenizer.Tokenizer at 0x7f5f3be13dd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# we want to import some llama source later\n",
    "os.getcwd()\n",
    "project_path = os.path.abspath(\"LLM\")\n",
    "\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "from llama.tokenizer import Tokenizer\n",
    "\n",
    "tok_path = \"/home/matt/.llama/checkpoints/Llama3.2-1B-hf-tok/tokenizer.model\"\n",
    "tok = Tokenizer(tok_path)\n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no pad:      [60704]\n",
      "pre-padded:  [12366]\n",
      "post-padded: [60704, 220]\n",
      "with colon:  [12366, 25]\n"
     ]
    }
   ],
   "source": [
    "print(f\"no pad:      {tok.encode(\"Paris\", bos=False, eos = False)}\")\n",
    "print(f\"pre-padded:  {tok.encode(\" Paris\", bos=False, eos = False)}\")\n",
    "print(f\"post-padded: {tok.encode(\"Paris \", bos=False, eos = False)}\")\n",
    "print(f\"with colon:  {tok.encode(\" Paris:\", bos=False, eos = False)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whitespace\n",
    "\n",
    "We see that tokens differ when whitespace is considered - so the first word in a setence may be a different ID to the same word inside the sentence. Usually sentences **are** preceded by a space, so we might as well do that.\n",
    "\n",
    "However we can add colons by the looks of things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: long, sentence:  How long has it been since you reviewed the objectives of your benefit and service program?, definitions: ['desire strongly or persistently', 'primarily temporal sense; being or indicating a relatively great or greater than average duration or passage of time or a duration as specified', 'primarily spatial sense; of relatively great or greater than average spatial extension or extension as specified', 'of relatively great height; - Sherwood Anderson', 'good at remembering', 'holding securities or commodities in expectation of a rise in prices', '(of speech sounds or syllables) of relatively long duration', 'involving substantial risk', 'planning prudently for the future', 'having or being more than normal or necessary:', 'for an extended time or at a distant time', 'for an extended distance']\n"
     ]
    }
   ],
   "source": [
    "sntc = sentence(row)\n",
    "defs = all_defs(row)\n",
    "word = row.word\n",
    "\n",
    "print(f\"word: {word}, sentence: {sntc}, definitions: {defs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence tokens: 2650 1317 706 433 1027 2533 499 22690 279 26470 315 701 8935 323 2532 2068 30\n"
     ]
    }
   ],
   "source": [
    "sntc_toks = tok.encode(sntc, bos=False, eos = False)\n",
    "\n",
    "print(\"sentence tokens: \" + \" \".join([str(i) for i in sntc_toks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tok = tok.encode(word, bos=False, eos = False)\n",
    "word_tok_pad = tok.encode( \" \" + word, bos=False, eos = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tok[0] in sntc_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tok_pad[0] in sntc_toks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying sub-token indices\n",
    "\n",
    "We will need to know which indices in the list of sentence tokens correspond to the word we want to disambiguate. There are some edge cases to bear in mind here, which we investigate below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tok_pad(row: series) -> List[int]:\n",
    "    word = row.word\n",
    "    word_tok_pad = tok.encode( \" \" + word, bos=False, eos = False)\n",
    "    return word_tok_pad\n",
    "\n",
    "def sentence_tok(row: series) -> List[int]:\n",
    "    sntc = sentence(row)\n",
    "    sntc_toks = tok.encode(sntc, bos=False, eos=False)\n",
    "    return sntc_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word_tok_pad\"] = df.apply(word_tok_pad, axis = 1)\n",
    "df[\"sentence_tok\"] = df.apply(sentence_tok, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "      <th>definitions</th>\n",
       "      <th>word_tok_pad</th>\n",
       "      <th>sentence_tok</th>\n",
       "      <th>word_tok_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>absenteeism</td>\n",
       "      <td>Do|you|measure|its|relation|to|reduced|absente...</td>\n",
       "      <td>7</td>\n",
       "      <td>absenteeism%1:04:00::</td>\n",
       "      <td>habitual absence from work</td>\n",
       "      <td>habitual absence from work</td>\n",
       "      <td>[94190, 2191]</td>\n",
       "      <td>[3234, 499, 6767, 1202, 12976, 311, 11293, 941...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>fancier</td>\n",
       "      <td>Is|it|larger|or|fancier|than|you|really|need|?</td>\n",
       "      <td>4</td>\n",
       "      <td>fancy%3:00:00::</td>\n",
       "      <td>not plain; decorative or ornamented</td>\n",
       "      <td>something many people believe that is false|a ...</td>\n",
       "      <td>[81697, 1291]</td>\n",
       "      <td>[2209, 433, 8294, 477, 81697, 1291, 1109, 499,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>purchasing agent</td>\n",
       "      <td>Is|your|purchasing agent|offering|too much|fre...</td>\n",
       "      <td>2</td>\n",
       "      <td>purchasing_agent%1:18:00::</td>\n",
       "      <td>an agent who purchases goods or services for a...</td>\n",
       "      <td>an agent who purchases goods or services for a...</td>\n",
       "      <td>[23395, 8479]</td>\n",
       "      <td>[2209, 701, 23395, 8479, 10209, 2288, 1790, 19...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word                                           sentence  \\\n",
       "27       absenteeism  Do|you|measure|its|relation|to|reduced|absente...   \n",
       "43           fancier     Is|it|larger|or|fancier|than|you|really|need|?   \n",
       "67  purchasing agent  Is|your|purchasing agent|offering|too much|fre...   \n",
       "\n",
       "    word_loc                     wordnet  \\\n",
       "27         7       absenteeism%1:04:00::   \n",
       "43         4             fancy%3:00:00::   \n",
       "67         2  purchasing_agent%1:18:00::   \n",
       "\n",
       "                                           definition  \\\n",
       "27                         habitual absence from work   \n",
       "43                not plain; decorative or ornamented   \n",
       "67  an agent who purchases goods or services for a...   \n",
       "\n",
       "                                          definitions   word_tok_pad  \\\n",
       "27                         habitual absence from work  [94190, 2191]   \n",
       "43  something many people believe that is false|a ...  [81697, 1291]   \n",
       "67  an agent who purchases goods or services for a...  [23395, 8479]   \n",
       "\n",
       "                                         sentence_tok  word_tok_len  \n",
       "27  [3234, 499, 6767, 1202, 12976, 311, 11293, 941...             2  \n",
       "43  [2209, 433, 8294, 477, 81697, 1291, 1109, 499,...             2  \n",
       "67  [2209, 701, 23395, 8479, 10209, 2288, 1790, 19...             2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"word_tok_len\"] = df.apply(lambda s : len(s.word_tok_pad), axis = 1)\n",
    "df[df['word_tok_len'] != 1].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that not all the words in out sample are just a single token, so we will need to be more general when checking that we can located the tokens in the sentence tokens: we want to check that they are present a a contiguous sub-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_contiguous_sublist(sublst, lst):\n",
    "    return str(sublst)[1:-1] in str(lst)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "      <th>definitions</th>\n",
       "      <th>word_tok_pad</th>\n",
       "      <th>sentence_tok</th>\n",
       "      <th>word_tok_len</th>\n",
       "      <th>word_locate_necc_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [word, sentence, word_loc, wordnet, definition, definitions, word_tok_pad, sentence_tok, word_tok_len, word_locate_necc_condition]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"word_locate_necc_condition\"] = df.apply(lambda s : contains_contiguous_sublist(s.word_tok_pad, s.sentence_tok), axis = 1)\n",
    "df[df.word_locate_necc_condition == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok - all our rows satisfy the necessary condition, however to truly locate the word we also need to identify which position it is in if there are two options; there is no reason this can't happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_contiguous_sublists(sublst, lst):\n",
    "    count = 0\n",
    "    i = 0\n",
    "    sub_len = len(sublst)\n",
    "\n",
    "    while i <= len(lst) - sub_len:\n",
    "        if lst[i:i + sub_len] == sublst:\n",
    "            count += 1\n",
    "            i += sub_len\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "      <th>definitions</th>\n",
       "      <th>word_tok_pad</th>\n",
       "      <th>sentence_tok</th>\n",
       "      <th>word_tok_len</th>\n",
       "      <th>word_locate_necc_condition</th>\n",
       "      <th>word_locate_possibilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [word, sentence, word_loc, wordnet, definition, definitions, word_tok_pad, sentence_tok, word_tok_len, word_locate_necc_condition, word_locate_possibilities]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"word_locate_possibilities\"] = df.apply(lambda s : count_contiguous_sublists(s.word_tok_pad, s.sentence_tok), axis = 1)\n",
    "df[df[\"word_locate_possibilities\"] != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately this data set doesn't contain an example, so we will have to come up with some test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_word_simple = \" that\"\n",
    "bad_sentence_simple = \" that thing you found, this is not that, that was another thing?\"\n",
    "\n",
    "bad_word_simple_toks     = tok.encode(bad_word_simple, bos = False, eos = False)\n",
    "bad_sentence_simple_toks = tok.encode(bad_sentence_simple, bos = False, eos = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[430]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_word_simple_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[430, 3245, 499, 1766, 11, 420, 374, 539, 430, 11, 430, 574, 2500, 3245, 30]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_sentence_simple_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_contiguous_sublists(bad_word_simple_toks, bad_sentence_simple_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/63413414/is-there-a-way-to-get-the-location-of-the-substring-from-which-a-certain-token-h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5)  that\n",
      "(5, 11)  thing\n",
      "(11, 15)  you\n",
      "(15, 21)  found\n",
      "(21, 22) ,\n",
      "(22, 27)  this\n",
      "(27, 30)  is\n",
      "(30, 34)  not\n",
      "(34, 39)  that\n",
      "(39, 40) ,\n",
      "(40, 45)  that\n",
      "(45, 49)  was\n",
      "(49, 57)  another\n",
      "(57, 63)  thing\n",
      "(63, 64) ?\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "for t in bad_sentence_simple_toks:\n",
    "    tok_word = tok.decode([t]) \n",
    "    \n",
    "    pos = bad_sentence_simple[i:].find(tok_word)\n",
    "\n",
    "    pos += i  \n",
    "\n",
    "    print(f\"({pos}, {pos + len(tok_word)}) {tok_word}\")\n",
    "\n",
    "    i = pos + len(tok_word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_start_index(s: series) -> int:\n",
    "    words = s.sentence.split('|')\n",
    "    ret = 1\n",
    "    for i in range(s.word_loc):\n",
    "        ret += len(words[i]) + 1 # the space\n",
    "    return ret\n",
    "\n",
    "\n",
    "def word_start_tok_index(s: series) -> int:\n",
    "\n",
    "    toks  = sentence_tok(s)\n",
    "\n",
    "    ret = 0\n",
    "    i = 0\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        tok_word = tok.decode([toks[ret]]) \n",
    "        \n",
    "        i += len(tok_word)\n",
    "        \n",
    "        if i >= s.word_start_index:\n",
    "            return ret\n",
    "        \n",
    "        ret += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word_start_index\"] = df.apply(word_start_index, axis = 1)\n",
    "df[\"word_start_tok_index\"] = df.apply(word_start_tok_index, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "      <th>definitions</th>\n",
       "      <th>word_tok_pad</th>\n",
       "      <th>sentence_tok</th>\n",
       "      <th>word_tok_len</th>\n",
       "      <th>word_locate_necc_condition</th>\n",
       "      <th>word_locate_possibilities</th>\n",
       "      <th>word_start_index</th>\n",
       "      <th>word_start_tok_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>How|long|has|it|been|since|you|reviewed|the|ob...</td>\n",
       "      <td>1</td>\n",
       "      <td>long%3:00:02::</td>\n",
       "      <td>primarily temporal sense; being or indicating ...</td>\n",
       "      <td>desire strongly or persistently|primarily temp...</td>\n",
       "      <td>[1317]</td>\n",
       "      <td>[2650, 1317, 706, 433, 1027, 2533, 499, 22690,...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>been</td>\n",
       "      <td>How|long|has|it|been|since|you|reviewed|the|ob...</td>\n",
       "      <td>4</td>\n",
       "      <td>be%2:42:03::</td>\n",
       "      <td>have the quality of being; (copula, used with ...</td>\n",
       "      <td>a light strong brittle grey toxic bivalent met...</td>\n",
       "      <td>[1027]</td>\n",
       "      <td>[2650, 1317, 706, 433, 1027, 2533, 499, 22690,...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reviewed</td>\n",
       "      <td>How|long|has|it|been|since|you|reviewed|the|ob...</td>\n",
       "      <td>7</td>\n",
       "      <td>review%2:31:00::</td>\n",
       "      <td>look at again; examine again</td>\n",
       "      <td>a new appraisal or evaluation|an essay or arti...</td>\n",
       "      <td>[22690]</td>\n",
       "      <td>[2650, 1317, 706, 433, 1027, 2533, 499, 22690,...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word                                           sentence  word_loc  \\\n",
       "0      long  How|long|has|it|been|since|you|reviewed|the|ob...         1   \n",
       "1      been  How|long|has|it|been|since|you|reviewed|the|ob...         4   \n",
       "2  reviewed  How|long|has|it|been|since|you|reviewed|the|ob...         7   \n",
       "\n",
       "            wordnet                                         definition  \\\n",
       "0    long%3:00:02::  primarily temporal sense; being or indicating ...   \n",
       "1      be%2:42:03::  have the quality of being; (copula, used with ...   \n",
       "2  review%2:31:00::                       look at again; examine again   \n",
       "\n",
       "                                         definitions word_tok_pad  \\\n",
       "0  desire strongly or persistently|primarily temp...       [1317]   \n",
       "1  a light strong brittle grey toxic bivalent met...       [1027]   \n",
       "2  a new appraisal or evaluation|an essay or arti...      [22690]   \n",
       "\n",
       "                                        sentence_tok  word_tok_len  \\\n",
       "0  [2650, 1317, 706, 433, 1027, 2533, 499, 22690,...             1   \n",
       "1  [2650, 1317, 706, 433, 1027, 2533, 499, 22690,...             1   \n",
       "2  [2650, 1317, 706, 433, 1027, 2533, 499, 22690,...             1   \n",
       "\n",
       "   word_locate_necc_condition  word_locate_possibilities  word_start_index  \\\n",
       "0                        True                          1                 5   \n",
       "1                        True                          1                17   \n",
       "2                        True                          1                32   \n",
       "\n",
       "   word_start_tok_index  \n",
       "0                     1  \n",
       "1                     4  \n",
       "2                     7  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "      <th>definitions</th>\n",
       "      <th>word_tok_pad</th>\n",
       "      <th>sentence_tok</th>\n",
       "      <th>word_tok_len</th>\n",
       "      <th>word_locate_necc_condition</th>\n",
       "      <th>word_locate_possibilities</th>\n",
       "      <th>word_start_index</th>\n",
       "      <th>word_start_tok_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>offering</td>\n",
       "      <td>Is|your|purchasing agent|offering|too much|fre...</td>\n",
       "      <td>3</td>\n",
       "      <td>offer%2:40:02::</td>\n",
       "      <td>make available or accessible, provide or furnish</td>\n",
       "      <td>the verbal act of offering|something offered (...</td>\n",
       "      <td>[10209]</td>\n",
       "      <td>[2209, 701, 23395, 8479, 10209, 2288, 1790, 19...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>eating</td>\n",
       "      <td>When|improvements|are|recommended|in|working|c...</td>\n",
       "      <td>14</td>\n",
       "      <td>eating%1:04:00::</td>\n",
       "      <td>the act of consuming food</td>\n",
       "      <td>the act of consuming food|take in solid food|e...</td>\n",
       "      <td>[12459]</td>\n",
       "      <td>[3277, 18637, 527, 11349, 304, 3318, 4787, 482...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>productivity</td>\n",
       "      <td>When|improvements|are|recommended|in|working|c...</td>\n",
       "      <td>30</td>\n",
       "      <td>productivity%1:07:00::</td>\n",
       "      <td>the quality of being productive or having the ...</td>\n",
       "      <td>the quality of being productive or having the ...</td>\n",
       "      <td>[26206]</td>\n",
       "      <td>[3277, 18637, 527, 11349, 304, 3318, 4787, 482...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word                                           sentence  word_loc  \\\n",
       "68      offering  Is|your|purchasing agent|offering|too much|fre...         3   \n",
       "80        eating  When|improvements|are|recommended|in|working|c...        14   \n",
       "85  productivity  When|improvements|are|recommended|in|working|c...        30   \n",
       "\n",
       "                   wordnet                                         definition  \\\n",
       "68         offer%2:40:02::   make available or accessible, provide or furnish   \n",
       "80        eating%1:04:00::                          the act of consuming food   \n",
       "85  productivity%1:07:00::  the quality of being productive or having the ...   \n",
       "\n",
       "                                          definitions word_tok_pad  \\\n",
       "68  the verbal act of offering|something offered (...      [10209]   \n",
       "80  the act of consuming food|take in solid food|e...      [12459]   \n",
       "85  the quality of being productive or having the ...      [26206]   \n",
       "\n",
       "                                         sentence_tok  word_tok_len  \\\n",
       "68  [2209, 701, 23395, 8479, 10209, 2288, 1790, 19...             1   \n",
       "80  [3277, 18637, 527, 11349, 304, 3318, 4787, 482...             1   \n",
       "85  [3277, 18637, 527, 11349, 304, 3318, 4787, 482...             1   \n",
       "\n",
       "    word_locate_necc_condition  word_locate_possibilities  word_start_index  \\\n",
       "68                        True                          1                26   \n",
       "80                        True                          1                91   \n",
       "85                        True                          1               184   \n",
       "\n",
       "    word_start_tok_index  \n",
       "68                     4  \n",
       "80                    15  \n",
       "85                    33  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.word_loc != df.word_start_tok_index].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see in that in cases when the setence contains words that require multiple tokens, this index based method is necessary - it also is robust to repeat instances of the same word!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forming definition prompts\n",
    "\n",
    "We need to find a way to include the word itself in the prompt containing the definition, for now we'll do the most basic, just appending it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_definition_prompts(s: series) -> List[str]:\n",
    "\n",
    "    encode = lambda  text : tok.encode(text, bos = False, eos = False)\n",
    "\n",
    "    if len(encode(\" \" + s.word)) == len(encode(\" \" + s.word + \":\")):\n",
    "        return Exception(\"colon was absorbed - changing token embedding!\")\n",
    "\n",
    "\n",
    "    defs = s.definitions.split('|')\n",
    "\n",
    "    return [\" \" + s.word + \": \" + d for d in defs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"definition_prompts\"] = df.apply(prepare_definition_prompts, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "      <th>definitions</th>\n",
       "      <th>word_tok_pad</th>\n",
       "      <th>sentence_tok</th>\n",
       "      <th>word_tok_len</th>\n",
       "      <th>word_locate_necc_condition</th>\n",
       "      <th>word_locate_possibilities</th>\n",
       "      <th>word_start_index</th>\n",
       "      <th>word_start_tok_index</th>\n",
       "      <th>definition_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>make</td>\n",
       "      <td>What|effort|do|you|make|to|assess|results|of|y...</td>\n",
       "      <td>4</td>\n",
       "      <td>make%2:41:00::</td>\n",
       "      <td>engage in</td>\n",
       "      <td>a recognizable kind|the act of mixing cards ha...</td>\n",
       "      <td>[1304]</td>\n",
       "      <td>[3639, 5149, 656, 499, 1304, 311, 8720, 3135, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>[ make: a recognizable kind,  make: the act of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>improved</td>\n",
       "      <td>Have|you|permitted|it|to|become|a|giveaway|pro...</td>\n",
       "      <td>17</td>\n",
       "      <td>improved%3:00:00::</td>\n",
       "      <td>made more desirable or valuable or profitable;...</td>\n",
       "      <td>to make better|get better|made more desirable ...</td>\n",
       "      <td>[13241]</td>\n",
       "      <td>[12522, 499, 15480, 433, 311, 3719, 264, 61064...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>17</td>\n",
       "      <td>[ improved: to make better,  improved: get bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>results</td>\n",
       "      <td>What|effort|do|you|make|to|assess|results|of|y...</td>\n",
       "      <td>7</td>\n",
       "      <td>result%1:11:00::</td>\n",
       "      <td>something that results</td>\n",
       "      <td>a phenomenon that follows and is caused by som...</td>\n",
       "      <td>[3135]</td>\n",
       "      <td>[3639, 5149, 656, 499, 1304, 311, 8720, 3135, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>[ results: a phenomenon that follows and is ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>benefits</td>\n",
       "      <td>When|negotiating|with|your|union|,|do|you|make...</td>\n",
       "      <td>16</td>\n",
       "      <td>benefit%1:21:00::</td>\n",
       "      <td>financial assistance in time of need</td>\n",
       "      <td>financial assistance in time of need|something...</td>\n",
       "      <td>[7720]</td>\n",
       "      <td>[3277, 44725, 449, 701, 11552, 11, 656, 499, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>16</td>\n",
       "      <td>[ benefits: financial assistance in time of ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word                                           sentence  word_loc  \\\n",
       "21      make  What|effort|do|you|make|to|assess|results|of|y...         4   \n",
       "14  improved  Have|you|permitted|it|to|become|a|giveaway|pro...        17   \n",
       "23   results  What|effort|do|you|make|to|assess|results|of|y...         7   \n",
       "94  benefits  When|negotiating|with|your|union|,|do|you|make...        16   \n",
       "\n",
       "               wordnet                                         definition  \\\n",
       "21      make%2:41:00::                                          engage in   \n",
       "14  improved%3:00:00::  made more desirable or valuable or profitable;...   \n",
       "23    result%1:11:00::                             something that results   \n",
       "94   benefit%1:21:00::               financial assistance in time of need   \n",
       "\n",
       "                                          definitions word_tok_pad  \\\n",
       "21  a recognizable kind|the act of mixing cards ha...       [1304]   \n",
       "14  to make better|get better|made more desirable ...      [13241]   \n",
       "23  a phenomenon that follows and is caused by som...       [3135]   \n",
       "94  financial assistance in time of need|something...       [7720]   \n",
       "\n",
       "                                         sentence_tok  word_tok_len  \\\n",
       "21  [3639, 5149, 656, 499, 1304, 311, 8720, 3135, ...             1   \n",
       "14  [12522, 499, 15480, 433, 311, 3719, 264, 61064...             1   \n",
       "23  [3639, 5149, 656, 499, 1304, 311, 8720, 3135, ...             1   \n",
       "94  [3277, 44725, 449, 701, 11552, 11, 656, 499, 1...             1   \n",
       "\n",
       "    word_locate_necc_condition  word_locate_possibilities  word_start_index  \\\n",
       "21                        True                          1                20   \n",
       "14                        True                          1                89   \n",
       "23                        True                          1                35   \n",
       "94                        True                          1                89   \n",
       "\n",
       "    word_start_tok_index                                 definition_prompts  \n",
       "21                     4  [ make: a recognizable kind,  make: the act of...  \n",
       "14                    17  [ improved: to make better,  improved: get bet...  \n",
       "23                     7  [ results: a phenomenon that follows and is ca...  \n",
       "94                    16  [ benefits: financial assistance in time of ne...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tokens(s: series) -> bool:\n",
    "    word_tok_pad = s.word_tok_pad[0]\n",
    "    word_tok_sentence = s.sentence_tok[s.word_start_tok_index]\n",
    "\n",
    "    return word_tok_pad == word_tok_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens_match\"] = df.apply(check_tokens, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "      <th>definitions</th>\n",
       "      <th>word_tok_pad</th>\n",
       "      <th>sentence_tok</th>\n",
       "      <th>word_tok_len</th>\n",
       "      <th>word_locate_necc_condition</th>\n",
       "      <th>word_locate_possibilities</th>\n",
       "      <th>word_start_index</th>\n",
       "      <th>word_start_tok_index</th>\n",
       "      <th>definition_prompts</th>\n",
       "      <th>tokens_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [word, sentence, word_loc, wordnet, definition, definitions, word_tok_pad, sentence_tok, word_tok_len, word_locate_necc_condition, word_locate_possibilities, word_start_index, word_start_tok_index, definition_prompts, tokens_match]\n",
       "Index: []"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"tokens_match\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WordSenseDisambiguation",
   "language": "python",
   "name": "wordsensedisambiguation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
