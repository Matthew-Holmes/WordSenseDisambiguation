{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemCore dataset\n",
    "\n",
    "In this notebook we'll break down how the SemCore dataset is organised, and see if it will come in useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "semcore_xml = \"Data/Raw/semcor.data.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The XML\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
    "<corpus lang=\"en\" source=\"semcor\">\n",
    "<text id=\"d000\" source=\"br-e30\">\n",
    "<sentence id=\"d000.s000\">\n",
    "<wf lemma=\"how\" pos=\"ADV\">How</wf>\n",
    "<instance id=\"d000.s000.t000\" lemma=\"long\" pos=\"ADJ\">long</instance>\n",
    "<wf lemma=\"have\" pos=\"VERB\">has</wf>\n",
    "<wf lemma=\"it\" pos=\"PRON\">it</wf>\n",
    "<instance id=\"d000.s000.t001\" lemma=\"be\" pos=\"VERB\">been</instance>\n",
    "<wf lemma=\"since\" pos=\"ADP\">since</wf>\n",
    "<wf lemma=\"you\" pos=\"PRON\">you</wf>\n",
    "<instance id=\"d000.s000.t002\" lemma=\"review\" pos=\"VERB\">reviewed</instance>\n",
    "<wf lemma=\"the\" pos=\"DET\">the</wf>\n",
    "<instance id=\"d000.s000.t003\" lemma=\"objective\" pos=\"NOUN\">objectives</instance>\n",
    "<wf lemma=\"of\" pos=\"ADP\">of</wf>\n",
    "<wf lemma=\"you\" pos=\"PRON\">your</wf>\n",
    "<instance id=\"d000.s000.t004\" lemma=\"benefit\" pos=\"NOUN\">benefit</instance>\n",
    "<wf lemma=\"and\" pos=\"CONJ\">and</wf>\n",
    "<instance id=\"d000.s000.t005\" lemma=\"service\" pos=\"NOUN\">service</instance>\n",
    "<instance id=\"d000.s000.t006\" lemma=\"program\" pos=\"NOUN\">program</instance>\n",
    "<wf lemma=\"?\" pos=\".\">?</wf>\n",
    "</sentence>\n",
    "...\n",
    "```\n",
    "\n",
    "We see a hierarchical data structure; corpus->text->sentence->(word form OR instance)\n",
    "\n",
    "Here we are interested primarily in the instance data, since they have a lookup key; a companion file was included that matches these to the WordNet semantic meaning for the word.\n",
    "\n",
    "For our purposes we don't care about the POS tagging, and are only interested in the instances. At cost of redundancy, we could convert this xml to a pandas dataframe which stores:\n",
    "* instance\n",
    "* source sentence\n",
    "* wordnet key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(semcore_xml)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root.tag='corpus'\n",
      "root.attrib={'lang': 'en', 'source': 'semcor'}\n"
     ]
    }
   ],
   "source": [
    "print(f'{root.tag=}')\n",
    "print(f'{root.attrib=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child.tag='text' child.attrib={'id': 'd000', 'source': 'br-e30'}\n",
      "child.tag='text' child.attrib={'id': 'd001', 'source': 'br-l15'}\n",
      "child.tag='text' child.attrib={'id': 'd002', 'source': 'br-f16'}\n",
      "child.tag='text' child.attrib={'id': 'd003', 'source': 'br-j42'}\n",
      "child.tag='text' child.attrib={'id': 'd004', 'source': 'br-g18'}\n",
      "child.tag='text' child.attrib={'id': 'd005', 'source': 'br-e26'}\n",
      "child.tag='text' child.attrib={'id': 'd006', 'source': 'br-f18'}\n",
      "child.tag='text' child.attrib={'id': 'd007', 'source': 'br-f24'}\n",
      "child.tag='text' child.attrib={'id': 'd008', 'source': 'br-n17'}\n",
      "child.tag='text' child.attrib={'id': 'd009', 'source': 'br-h17'}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for child in root:\n",
    "    print(f'{child.tag=}', f'{child.attrib=}')\n",
    "    i = i + 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 352/352 [00:00<00:00, 412.65it/s]\n"
     ]
    }
   ],
   "source": [
    "all_sentences = []\n",
    "\n",
    "for text_el in tqdm(root.findall('text')):\n",
    "    text_id = text_el.get('id')\n",
    "\n",
    "    for sentence_el in text_el.findall('sentence'):\n",
    "        sentence_id = sentence_el.get('id')\n",
    "        sentence_tokens = []\n",
    "\n",
    "        for token_el in sentence_el:\n",
    "            token_info = {\n",
    "                'tag': token_el.tag,                # 'wf' or 'instance'\n",
    "                'word': token_el.text,\n",
    "                'lemma': token_el.get('lemma'),\n",
    "                'pos': token_el.get('pos'),\n",
    "                'id': token_el.get('id')           # only present if tag == 'instance'\n",
    "            }\n",
    "            sentence_tokens.append(token_info)\n",
    "\n",
    "        all_sentences.append({\n",
    "            'text_id': text_id,\n",
    "            'sentence_id': sentence_id,\n",
    "            'tokens': sentence_tokens\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have\n",
      "you\n",
      "permitted\n",
      "it\n",
      "to\n",
      "become\n",
      "a\n",
      "giveaway\n",
      "program\n",
      "rather\n",
      "than\n",
      "one\n",
      "that\n",
      "has\n",
      "the\n",
      "goal\n",
      "of\n",
      "improved\n",
      "employee\n",
      "morale\n",
      "and\n",
      ",\n",
      "consequently\n",
      ",\n",
      "increased\n",
      "productivity\n",
      "?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(item['word']) for item in all_sentences[1]['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python WSD",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
