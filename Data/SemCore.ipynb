{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemCore dataset\n",
    "\n",
    "In this notebook we'll break down how the SemCore dataset is organised, and see if it will come in useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "semcore_xml  = \"Data/Raw/semcor.data.xml\"\n",
    "wordnet_keys = \"Data/Raw/semcor.gold.key.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The XML\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
    "<corpus lang=\"en\" source=\"semcor\">\n",
    "<text id=\"d000\" source=\"br-e30\">\n",
    "<sentence id=\"d000.s000\">\n",
    "<wf lemma=\"how\" pos=\"ADV\">How</wf>\n",
    "<instance id=\"d000.s000.t000\" lemma=\"long\" pos=\"ADJ\">long</instance>\n",
    "<wf lemma=\"have\" pos=\"VERB\">has</wf>\n",
    "<wf lemma=\"it\" pos=\"PRON\">it</wf>\n",
    "<instance id=\"d000.s000.t001\" lemma=\"be\" pos=\"VERB\">been</instance>\n",
    "<wf lemma=\"since\" pos=\"ADP\">since</wf>\n",
    "<wf lemma=\"you\" pos=\"PRON\">you</wf>\n",
    "<instance id=\"d000.s000.t002\" lemma=\"review\" pos=\"VERB\">reviewed</instance>\n",
    "<wf lemma=\"the\" pos=\"DET\">the</wf>\n",
    "<instance id=\"d000.s000.t003\" lemma=\"objective\" pos=\"NOUN\">objectives</instance>\n",
    "<wf lemma=\"of\" pos=\"ADP\">of</wf>\n",
    "<wf lemma=\"you\" pos=\"PRON\">your</wf>\n",
    "<instance id=\"d000.s000.t004\" lemma=\"benefit\" pos=\"NOUN\">benefit</instance>\n",
    "<wf lemma=\"and\" pos=\"CONJ\">and</wf>\n",
    "<instance id=\"d000.s000.t005\" lemma=\"service\" pos=\"NOUN\">service</instance>\n",
    "<instance id=\"d000.s000.t006\" lemma=\"program\" pos=\"NOUN\">program</instance>\n",
    "<wf lemma=\"?\" pos=\".\">?</wf>\n",
    "</sentence>\n",
    "...\n",
    "```\n",
    "\n",
    "We see a hierarchical data structure; corpus->text->sentence->(word form OR instance)\n",
    "\n",
    "Here we are interested primarily in the instance data, since they have a lookup key; a companion file was included that matches these to the WordNet semantic meaning for the word.\n",
    "\n",
    "For our purposes we don't care about the POS tagging, and are only interested in the instances. At cost of redundancy, we could convert this xml to a pandas dataframe which stores:\n",
    "* instance\n",
    "* source sentence\n",
    "* wordnet key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(semcore_xml)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root.tag='corpus'\n",
      "root.attrib={'lang': 'en', 'source': 'semcor'}\n"
     ]
    }
   ],
   "source": [
    "print(f'{root.tag=}')\n",
    "print(f'{root.attrib=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child.tag='text' child.attrib={'id': 'd000', 'source': 'br-e30'}\n",
      "child.tag='text' child.attrib={'id': 'd001', 'source': 'br-l15'}\n",
      "child.tag='text' child.attrib={'id': 'd002', 'source': 'br-f16'}\n",
      "child.tag='text' child.attrib={'id': 'd003', 'source': 'br-j42'}\n",
      "child.tag='text' child.attrib={'id': 'd004', 'source': 'br-g18'}\n",
      "child.tag='text' child.attrib={'id': 'd005', 'source': 'br-e26'}\n",
      "child.tag='text' child.attrib={'id': 'd006', 'source': 'br-f18'}\n",
      "child.tag='text' child.attrib={'id': 'd007', 'source': 'br-f24'}\n",
      "child.tag='text' child.attrib={'id': 'd008', 'source': 'br-n17'}\n",
      "child.tag='text' child.attrib={'id': 'd009', 'source': 'br-h17'}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for child in root:\n",
    "    print(f'{child.tag=}', f'{child.attrib=}')\n",
    "    i = i + 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 352/352 [00:00<00:00, 359.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 37176 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_sentences = []\n",
    "\n",
    "for text_el in tqdm(root.findall('text')):\n",
    "    text_id = text_el.get('id')\n",
    "\n",
    "    for sentence_el in text_el.findall('sentence'):\n",
    "        sentence_id = sentence_el.get('id')\n",
    "        sentence_tokens = []\n",
    "\n",
    "        for token_el in sentence_el:\n",
    "            token_info = {\n",
    "                'tag': token_el.tag,                # 'wf' or 'instance'\n",
    "                'word': token_el.text,\n",
    "                'lemma': token_el.get('lemma'),\n",
    "                'pos': token_el.get('pos'),\n",
    "                'id': token_el.get('id')           # only present if tag == 'instance'\n",
    "            }\n",
    "            sentence_tokens.append(token_info)\n",
    "\n",
    "        all_sentences.append({\n",
    "            'text_id': text_id,\n",
    "            'sentence_id': sentence_id,\n",
    "            'tokens': sentence_tokens\n",
    "        })\n",
    "\n",
    "\n",
    "print(f\"found {len(all_sentences)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    \n",
    "    sentence_text = \" \".join([token['word'] for token in sentence['tokens']])\n",
    "\n",
    "    records = []\n",
    "\n",
    "    \n",
    "    for idx, token in enumerate(sentence['tokens']):\n",
    "        if token['tag'] == 'instance':\n",
    "            record = {\n",
    "                'word'            : token['word'],\n",
    "                'wordnet_join_id' : token['id'],\n",
    "                'sentence'        : sentence_text,\n",
    "                'word_loc'        : idx\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/37176 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 37176/37176 [00:00<00:00, 56436.30it/s]\n"
     ]
    }
   ],
   "source": [
    "row_data = [record for sentence in tqdm(all_sentences) for record in process_sentence(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>wordnet_join_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>d000.s000.t000</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>been</td>\n",
       "      <td>d000.s000.t001</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reviewed</td>\n",
       "      <td>d000.s000.t002</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>objectives</td>\n",
       "      <td>d000.s000.t003</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit</td>\n",
       "      <td>d000.s000.t004</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word wordnet_join_id  \\\n",
       "0        long  d000.s000.t000   \n",
       "1        been  d000.s000.t001   \n",
       "2    reviewed  d000.s000.t002   \n",
       "3  objectives  d000.s000.t003   \n",
       "4     benefit  d000.s000.t004   \n",
       "\n",
       "                                            sentence  word_loc  \n",
       "0  How long has it been since you reviewed the ob...         1  \n",
       "1  How long has it been since you reviewed the ob...         4  \n",
       "2  How long has it been since you reviewed the ob...         7  \n",
       "3  How long has it been since you reviewed the ob...         9  \n",
       "4  How long has it been since you reviewed the ob...        12  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(row_data)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging in the wordnet keys\n",
    "\n",
    "These link up the \"instances\" to wordnet definitions\n",
    "\n",
    "```csv\n",
    "d000.s000.t000 long%3:00:02::\n",
    "d000.s000.t001 be%2:42:03::\n",
    "d000.s000.t002 review%2:31:00::\n",
    "d000.s000.t003 objective%1:09:00::\n",
    "d000.s000.t004 benefit%1:21:00::\n",
    "d000.s000.t005 service%1:04:07::\n",
    "```\n",
    "\n",
    "Most take this form:\n",
    "\n",
    "`lemma%ss_type:lex_filenum:lex_id::`\n",
    "\n",
    "However there is special consideration for satellite adjectives and occasionally multiple word senses:\n",
    "\n",
    "```\n",
    "improved%5:00:00:better:00\n",
    "public%5:00:00:common:02 public%3:00:00:\n",
    "```\n",
    "\n",
    "For now I'll merge these in as strings, then see what the wordnet data looks like to decide how to handle the edge cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "226036it [00:00, 437342.53it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "with open(wordnet_keys, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f):\n",
    "        parts = line.strip().split(\" \", 1)\n",
    "        local_key, wordnet_id = parts\n",
    "        data.append((local_key, wordnet_id))\n",
    "\n",
    "wordnet_merge_df = pd.DataFrame(data, columns=[\"wordnet_join_id\", \"wordnet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordnet_join_id</th>\n",
       "      <th>wordnet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>d000.s010.t003</td>\n",
       "      <td>free%3:00:00::</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>d000.s010.t004</td>\n",
       "      <td>buying%1:04:00::</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>d000.s010.t005</td>\n",
       "      <td>service%1:14:05:: service%1:04:00::</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>d000.s010.t006</td>\n",
       "      <td>employee%1:18:00::</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>d000.s011.t000</td>\n",
       "      <td>improvement%1:04:00::</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wordnet_join_id                              wordnet\n",
       "70  d000.s010.t003                       free%3:00:00::\n",
       "71  d000.s010.t004                     buying%1:04:00::\n",
       "72  d000.s010.t005  service%1:14:05:: service%1:04:00::\n",
       "73  d000.s010.t006                   employee%1:18:00::\n",
       "74  d000.s011.t000                improvement%1:04:00::"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_merge_df.iloc[70:75] # check the wordnet ids without spaces aren't messed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(wordnet_merge_df).drop(columns= ['wordnet_join_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>1</td>\n",
       "      <td>long%3:00:02::</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>been</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>4</td>\n",
       "      <td>be%2:42:03::</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reviewed</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>7</td>\n",
       "      <td>review%2:31:00::</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>objectives</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>9</td>\n",
       "      <td>objective%1:09:00::</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>12</td>\n",
       "      <td>benefit%1:21:00::</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word                                           sentence  word_loc  \\\n",
       "0        long  How long has it been since you reviewed the ob...         1   \n",
       "1        been  How long has it been since you reviewed the ob...         4   \n",
       "2    reviewed  How long has it been since you reviewed the ob...         7   \n",
       "3  objectives  How long has it been since you reviewed the ob...         9   \n",
       "4     benefit  How long has it been since you reviewed the ob...        12   \n",
       "\n",
       "               wordnet  \n",
       "0       long%3:00:02::  \n",
       "1         be%2:42:03::  \n",
       "2     review%2:31:00::  \n",
       "3  objective%1:09:00::  \n",
       "4    benefit%1:21:00::  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting definitions from WordNet\n",
    "\n",
    "The wordnet files can be grabbed using the `nltk` package, so we don't need to worry about too much manual work now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/matt/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_sense_key='long%3:00:02::'\n"
     ]
    }
   ],
   "source": [
    "demo_sense_key = df.iloc[0][\"wordnet\"]\n",
    "print(f\"{demo_sense_key=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: long\n",
      "Synset: long.a.01\n",
      "Definition: primarily temporal sense; being or indicating a relatively great or greater than average duration or passage of time or a duration as specified\n",
      "Examples: ['a long life', 'a long boring speech', 'a long time', 'a long friendship', 'a long game', 'long ago', 'an hour long']\n"
     ]
    }
   ],
   "source": [
    "lemma = wn.lemma_from_key(demo_sense_key)\n",
    "\n",
    "synset = lemma.synset()\n",
    "\n",
    "print(f\"Word: {lemma.name()}\")\n",
    "print(f\"Synset: {synset.name()}\")\n",
    "print(f\"Definition: {synset.definition()}\")\n",
    "print(f\"Examples: {synset.examples()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_from_sense_key(key):\n",
    "    lemma = wn.lemma_from_key(key)\n",
    "    synset = lemma.synset()\n",
    "    return synset.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling edge case\n",
    "\n",
    "First lets see how it copes with the satellite adjectives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'become or made better in quality'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_from_sense_key('improved%5:00:00:better:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "those work, what about when there are two?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdef_from_sense_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpublic\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m5:00:00:common:02 public\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m3:00:00:\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m, in \u001b[0;36mdef_from_sense_key\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdef_from_sense_key\u001b[39m(key):\n\u001b[0;32m----> 2\u001b[0m     lemma \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemma_from_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     synset \u001b[38;5;241m=\u001b[39m lemma\u001b[38;5;241m.\u001b[39msynset()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m synset\u001b[38;5;241m.\u001b[39mdefinition()\n",
      "File \u001b[0;32m/mnt/c/Users/Matt/Projects/WordSenseDisambiguation/.venv/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1484\u001b[0m, in \u001b[0;36mWordNetCorpusReader.lemma_from_key\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlemma_from_key\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1481\u001b[0m     \u001b[38;5;66;03m# Keys are case sensitive and always lower-case\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m     key \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m-> 1484\u001b[0m     lemma_name, lex_sense \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1485\u001b[0m     pos_number, lexname_index, lex_id, _, _ \u001b[38;5;241m=\u001b[39m lex_sense\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1486\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos_names[\u001b[38;5;28mint\u001b[39m(pos_number)]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def_from_sense_key('public%5:00:00:common:02 public%3:00:00:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That throws, lets see what the two definitions would have been:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def 1 is affecting the people or community as a whole\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef 1 is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdef_from_sense_key(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublic\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m5:00:00:common:02\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef 2 is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdef_from_sense_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpublic\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m3:00:00:\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m, in \u001b[0;36mdef_from_sense_key\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdef_from_sense_key\u001b[39m(key):\n\u001b[0;32m----> 2\u001b[0m     lemma \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemma_from_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     synset \u001b[38;5;241m=\u001b[39m lemma\u001b[38;5;241m.\u001b[39msynset()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m synset\u001b[38;5;241m.\u001b[39mdefinition()\n",
      "File \u001b[0;32m/mnt/c/Users/Matt/Projects/WordSenseDisambiguation/.venv/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1485\u001b[0m, in \u001b[0;36mWordNetCorpusReader.lemma_from_key\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1482\u001b[0m key \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m   1484\u001b[0m lemma_name, lex_sense \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1485\u001b[0m pos_number, lexname_index, lex_id, _, _ \u001b[38;5;241m=\u001b[39m lex_sense\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1486\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos_names[\u001b[38;5;28mint\u001b[39m(pos_number)]\n\u001b[1;32m   1488\u001b[0m \u001b[38;5;66;03m# open the key -> synset file if necessary\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "print(f\"def 1 is {def_from_sense_key('public%5:00:00:common:02')}\")\n",
    "print(f\"def 2 is {def_from_sense_key('public%3:00:00:')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets just use the first one in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_from_sense_key(key):\n",
    "    key = key.split(\" \")[0]\n",
    "    lemma = wn.lemma_from_key(key)\n",
    "    synset = lemma.synset()\n",
    "    return synset.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 226036/226036 [00:22<00:00, 10131.24it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['definition'] = df['wordnet'].progress_apply(def_from_sense_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45421</th>\n",
       "      <td>feel</td>\n",
       "      <td>You feel him every mile further away .</td>\n",
       "      <td>1</td>\n",
       "      <td>feel%2:39:00::</td>\n",
       "      <td>perceive by a physical sensation, e.g., coming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72057</th>\n",
       "      <td>enrichment</td>\n",
       "      <td>It is possible that the idea of enrichment of ...</td>\n",
       "      <td>7</td>\n",
       "      <td>enrichment%1:04:00::</td>\n",
       "      <td>act of making fuller or more meaningful or rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115019</th>\n",
       "      <td>newly</td>\n",
       "      <td>This appears to result from both a reduced amo...</td>\n",
       "      <td>19</td>\n",
       "      <td>newly%4:02:00::</td>\n",
       "      <td>very recently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154614</th>\n",
       "      <td>adjournment</td>\n",
       "      <td>Before adjournment Monday afternoon , the Sena...</td>\n",
       "      <td>1</td>\n",
       "      <td>adjournment%1:04:00::</td>\n",
       "      <td>the termination of a meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204776</th>\n",
       "      <td>spread</td>\n",
       "      <td>The soldiers themselves cannot stage a success...</td>\n",
       "      <td>17</td>\n",
       "      <td>spread%2:35:00::</td>\n",
       "      <td>distribute or disperse widely</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word                                           sentence  \\\n",
       "45421          feel             You feel him every mile further away .   \n",
       "72057    enrichment  It is possible that the idea of enrichment of ...   \n",
       "115019        newly  This appears to result from both a reduced amo...   \n",
       "154614  adjournment  Before adjournment Monday afternoon , the Sena...   \n",
       "204776       spread  The soldiers themselves cannot stage a success...   \n",
       "\n",
       "        word_loc                wordnet  \\\n",
       "45421          1         feel%2:39:00::   \n",
       "72057          7   enrichment%1:04:00::   \n",
       "115019        19        newly%4:02:00::   \n",
       "154614         1  adjournment%1:04:00::   \n",
       "204776        17       spread%2:35:00::   \n",
       "\n",
       "                                               definition  \n",
       "45421   perceive by a physical sensation, e.g., coming...  \n",
       "72057   act of making fuller or more meaningful or rew...  \n",
       "115019                                      very recently  \n",
       "154614                       the termination of a meeting  \n",
       "204776                      distribute or disperse widely  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including all the possible definitions\n",
    "\n",
    "These will be the items that a model must distinguish between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def options_from_key(key):\n",
    "\n",
    "    word = key.split(\"%\")[0]\n",
    "\n",
    "    synsets = wn.synsets(word)\n",
    "    \n",
    "    defs = []\n",
    "\n",
    "    for syn in synsets:\n",
    "        this_def = syn.definition()\n",
    "        if '|' in this_def:\n",
    "            raise Exception(f\"forbidden character in: {this_def}, for {word}\")\n",
    "        defs.append(syn.definition())\n",
    "        \n",
    "\n",
    "    return \"|\".join(defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the termination of a meeting|the act of postponing to another time or place'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_from_key('adjournment%1:04:00::')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 226036/226036 [00:10<00:00, 21544.58it/s]\n"
     ]
    }
   ],
   "source": [
    "df['definitions'] = df['wordnet'].progress_apply(options_from_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "      <th>wordnet</th>\n",
       "      <th>definition</th>\n",
       "      <th>definitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47643</th>\n",
       "      <td>study</td>\n",
       "      <td>No one will deny that such broad developments ...</td>\n",
       "      <td>17</td>\n",
       "      <td>study%1:04:00::</td>\n",
       "      <td>a detailed critical inspection</td>\n",
       "      <td>a detailed critical inspection|applying the mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204758</th>\n",
       "      <td>adds up</td>\n",
       "      <td>Even so , it adds up to impossible odds , exce...</td>\n",
       "      <td>4</td>\n",
       "      <td>add_up%2:42:01::</td>\n",
       "      <td>develop into</td>\n",
       "      <td>develop into|determine the sum of|add up in nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>permanently</td>\n",
       "      <td>Second , they believed it important to determi...</td>\n",
       "      <td>19</td>\n",
       "      <td>permanently%4:02:00::</td>\n",
       "      <td>for a long time without essential change</td>\n",
       "      <td>for a long time without essential change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106607</th>\n",
       "      <td>plane</td>\n",
       "      <td>Also , planetary gravitational attraction incr...</td>\n",
       "      <td>10</td>\n",
       "      <td>plane%1:25:00::</td>\n",
       "      <td>(mathematics) an unbounded two-dimensional shape</td>\n",
       "      <td>an aircraft that has a fixed wing and is power...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100392</th>\n",
       "      <td>liked</td>\n",
       "      <td>The dialogue is sharp , witty and candid - typ...</td>\n",
       "      <td>38</td>\n",
       "      <td>like%2:37:05::</td>\n",
       "      <td>find enjoyable or agreeable</td>\n",
       "      <td>a similar kind; ,|a kind of person|prefer or w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word                                           sentence  \\\n",
       "47643         study  No one will deny that such broad developments ...   \n",
       "204758      adds up  Even so , it adds up to impossible odds , exce...   \n",
       "2160    permanently  Second , they believed it important to determi...   \n",
       "106607        plane  Also , planetary gravitational attraction incr...   \n",
       "100392        liked  The dialogue is sharp , witty and candid - typ...   \n",
       "\n",
       "        word_loc                wordnet  \\\n",
       "47643         17        study%1:04:00::   \n",
       "204758         4       add_up%2:42:01::   \n",
       "2160          19  permanently%4:02:00::   \n",
       "106607        10        plane%1:25:00::   \n",
       "100392        38         like%2:37:05::   \n",
       "\n",
       "                                              definition  \\\n",
       "47643                     a detailed critical inspection   \n",
       "204758                                      develop into   \n",
       "2160            for a long time without essential change   \n",
       "106607  (mathematics) an unbounded two-dimensional shape   \n",
       "100392                       find enjoyable or agreeable   \n",
       "\n",
       "                                              definitions  \n",
       "47643   a detailed critical inspection|applying the mi...  \n",
       "204758  develop into|determine the sum of|add up in nu...  \n",
       "2160             for a long time without essential change  \n",
       "106607  an aircraft that has a fixed wing and is power...  \n",
       "100392  a similar kind; ,|a kind of person|prefer or w...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Data/Processed/SemCoreProcessed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python WSD",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
