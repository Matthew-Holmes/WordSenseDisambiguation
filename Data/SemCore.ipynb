{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemCore dataset\n",
    "\n",
    "In this notebook we'll break down how the SemCore dataset is organised, and see if it will come in useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "semcore_xml = \"Data/Raw/semcor.data.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The XML\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
    "<corpus lang=\"en\" source=\"semcor\">\n",
    "<text id=\"d000\" source=\"br-e30\">\n",
    "<sentence id=\"d000.s000\">\n",
    "<wf lemma=\"how\" pos=\"ADV\">How</wf>\n",
    "<instance id=\"d000.s000.t000\" lemma=\"long\" pos=\"ADJ\">long</instance>\n",
    "<wf lemma=\"have\" pos=\"VERB\">has</wf>\n",
    "<wf lemma=\"it\" pos=\"PRON\">it</wf>\n",
    "<instance id=\"d000.s000.t001\" lemma=\"be\" pos=\"VERB\">been</instance>\n",
    "<wf lemma=\"since\" pos=\"ADP\">since</wf>\n",
    "<wf lemma=\"you\" pos=\"PRON\">you</wf>\n",
    "<instance id=\"d000.s000.t002\" lemma=\"review\" pos=\"VERB\">reviewed</instance>\n",
    "<wf lemma=\"the\" pos=\"DET\">the</wf>\n",
    "<instance id=\"d000.s000.t003\" lemma=\"objective\" pos=\"NOUN\">objectives</instance>\n",
    "<wf lemma=\"of\" pos=\"ADP\">of</wf>\n",
    "<wf lemma=\"you\" pos=\"PRON\">your</wf>\n",
    "<instance id=\"d000.s000.t004\" lemma=\"benefit\" pos=\"NOUN\">benefit</instance>\n",
    "<wf lemma=\"and\" pos=\"CONJ\">and</wf>\n",
    "<instance id=\"d000.s000.t005\" lemma=\"service\" pos=\"NOUN\">service</instance>\n",
    "<instance id=\"d000.s000.t006\" lemma=\"program\" pos=\"NOUN\">program</instance>\n",
    "<wf lemma=\"?\" pos=\".\">?</wf>\n",
    "</sentence>\n",
    "...\n",
    "```\n",
    "\n",
    "We see a hierarchical data structure; corpus->text->sentence->(word form OR instance)\n",
    "\n",
    "Here we are interested primarily in the instance data, since they have a lookup key; a companion file was included that matches these to the WordNet semantic meaning for the word.\n",
    "\n",
    "For our purposes we don't care about the POS tagging, and are only interested in the instances. At cost of redundancy, we could convert this xml to a pandas dataframe which stores:\n",
    "* instance\n",
    "* source sentence\n",
    "* wordnet key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(semcore_xml)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root.tag='corpus'\n",
      "root.attrib={'lang': 'en', 'source': 'semcor'}\n"
     ]
    }
   ],
   "source": [
    "print(f'{root.tag=}')\n",
    "print(f'{root.attrib=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child.tag='text' child.attrib={'id': 'd000', 'source': 'br-e30'}\n",
      "child.tag='text' child.attrib={'id': 'd001', 'source': 'br-l15'}\n",
      "child.tag='text' child.attrib={'id': 'd002', 'source': 'br-f16'}\n",
      "child.tag='text' child.attrib={'id': 'd003', 'source': 'br-j42'}\n",
      "child.tag='text' child.attrib={'id': 'd004', 'source': 'br-g18'}\n",
      "child.tag='text' child.attrib={'id': 'd005', 'source': 'br-e26'}\n",
      "child.tag='text' child.attrib={'id': 'd006', 'source': 'br-f18'}\n",
      "child.tag='text' child.attrib={'id': 'd007', 'source': 'br-f24'}\n",
      "child.tag='text' child.attrib={'id': 'd008', 'source': 'br-n17'}\n",
      "child.tag='text' child.attrib={'id': 'd009', 'source': 'br-h17'}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for child in root:\n",
    "    print(f'{child.tag=}', f'{child.attrib=}')\n",
    "    i = i + 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 352/352 [00:00<00:00, 359.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 37176 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_sentences = []\n",
    "\n",
    "for text_el in tqdm(root.findall('text')):\n",
    "    text_id = text_el.get('id')\n",
    "\n",
    "    for sentence_el in text_el.findall('sentence'):\n",
    "        sentence_id = sentence_el.get('id')\n",
    "        sentence_tokens = []\n",
    "\n",
    "        for token_el in sentence_el:\n",
    "            token_info = {\n",
    "                'tag': token_el.tag,                # 'wf' or 'instance'\n",
    "                'word': token_el.text,\n",
    "                'lemma': token_el.get('lemma'),\n",
    "                'pos': token_el.get('pos'),\n",
    "                'id': token_el.get('id')           # only present if tag == 'instance'\n",
    "            }\n",
    "            sentence_tokens.append(token_info)\n",
    "\n",
    "        all_sentences.append({\n",
    "            'text_id': text_id,\n",
    "            'sentence_id': sentence_id,\n",
    "            'tokens': sentence_tokens\n",
    "        })\n",
    "\n",
    "\n",
    "print(f\"found {len(all_sentences)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    \n",
    "    sentence_text = \" \".join([token['word'] for token in sentence['tokens']])\n",
    "\n",
    "    records = []\n",
    "\n",
    "    \n",
    "    for idx, token in enumerate(sentence['tokens']):\n",
    "        if token['tag'] == 'instance':\n",
    "            record = {\n",
    "                'word'            : token['word'],\n",
    "                'wordnet_join_id' : token['id'],\n",
    "                'sentence'        : sentence_text,\n",
    "                'word_loc'        : idx\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 37176/37176 [00:00<00:00, 63058.57it/s]\n"
     ]
    }
   ],
   "source": [
    "row_data = [record for sentence in tqdm(all_sentences) for record in process_sentence(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>wordnet_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>d000.s000.t000</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>been</td>\n",
       "      <td>d000.s000.t001</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reviewed</td>\n",
       "      <td>d000.s000.t002</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>objectives</td>\n",
       "      <td>d000.s000.t003</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit</td>\n",
       "      <td>d000.s000.t004</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word      wordnet_id  \\\n",
       "0        long  d000.s000.t000   \n",
       "1        been  d000.s000.t001   \n",
       "2    reviewed  d000.s000.t002   \n",
       "3  objectives  d000.s000.t003   \n",
       "4     benefit  d000.s000.t004   \n",
       "\n",
       "                                            sentence  word_loc  \n",
       "0  How long has it been since you reviewed the ob...         1  \n",
       "1  How long has it been since you reviewed the ob...         4  \n",
       "2  How long has it been since you reviewed the ob...         7  \n",
       "3  How long has it been since you reviewed the ob...         9  \n",
       "4  How long has it been since you reviewed the ob...        12  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(row_data)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python WSD",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
